{"num_epoch": 20,
  "batch_size": 1024,
  "optimizer": "adam",
  "adam_lr": 1e-4,
  "latent_dim": 8,
  "latent_dim_mlp": 8,
  "l2_regularization": 0.0001,
  "topk": 10,
  "augment_neg_number" : 4,
  "layers": [16,64,32,16,8]}